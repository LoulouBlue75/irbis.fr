# üåä PROJET ABYSS : STRAT√âGIE TEMPORELLE & ARCHIVES

> **Objectif** : Valoriser le "Deep Data" (archives, emails, notes) en int√©grant la dimension temporelle pour ne pas polluer le syst√®me avec des donn√©es obsol√®tes.

---

## 1. Le D√©fi : La "Demi-Vie" de la Donn√©e
Une note sur un candidat datant de 2021 n'a pas la m√™me valeur qu'un email de 2024.
*   **Risque** : Le RAG classique (Vector Search) ne voit que la similarit√© s√©mantique, pas la fra√Æcheur.
*   **Solution** : Le **Temporal Context Engine**.

---

## 2. Architecture du Moteur Temporel

### A. Mod√®le de Donn√©es (Metadatas)
Chaque "chunk" de donn√©e vectoris√© doit poss√©der ces m√©tadonn√©es :
```json
{
  "content": "Expert React...",
  "source_type": "email_archive",
  "source_date": "2021-05-12T10:00:00Z", // Date de l'info
  "ingested_at": "2024-12-20T20:00:00Z", // Date du traitement
  "validity_period_months": 24, // Dur√©e de vie estim√©e
  "decay_rate": 0.5 // Vitesse de d√©pr√©ciation
}
```

### B. La "Decay Function" (Fonction de D√©pr√©ciation)
Au moment du *retrieval* (recherche), on applique un score hybride :
$$ ScoreFinal = ScoreS√©mantique \times \frac{1}{1 + (\text{AgeEnAnn√©es} \times DecayRate)} $$

*   **Exemple** : Un CV parfait (Score 0.95) mais vieux de 3 ans (Age 3) avec un decay de 0.5 vaudra : $0.95 \times (1 / 2.5) = 0.38$.
*   **R√©sultat** : Il ressortira *apr√®s* un CV moyen (0.7) mais r√©cent (2024).

---

## 3. Pipeline d'Ingestion (Inngest)

### Workflow : `ingest/archive-batch`
Ce workflow traite vos exports d'emails et dossiers.

1.  **Extraction & Datation (LLM)** :
    *   Le LLM ne doit pas juste extraire le texte, il doit **d√©duire la date de validit√©**.
    *   *Prompt* : "Extrais les comp√©tences ET la date de ce document. Si pas de date, estime-la via le contexte."
2.  **Calcul du Score Initial** :
    *   Si la donn√©e est > 3 ans, on la marque `stale` (p√©rim√©e) mais on la garde pour l'historique ("Memory").
3.  **Vectorisation Temporelle** :
    *   Stockage dans Supabase `vectors` avec les m√©tadonn√©es temporelles.

---

## 4. Orchestration de la "Fra√Æcheur" (Re-validation)

C'est l√† qu'Inngest brille. On ne subit pas l'obsolescence, on la g√®re.

### Workflow : `cron/refresh-stale-profiles`
*   **Trigger** : Hebdomadaire.
*   **Action** :
    1.  Scanner les profils "High Potential" dont la derni√®re data > 12 mois.
    2.  **Action Agentique** : Lancer une recherche LinkedIn/Web pour voir si le profil a chang√©.
    3.  **Comparaison** :
        *   Si changement d√©tect√© -> Cr√©er nouvelle entr√©e (2024) -> Le score remonte.
        *   Si pas de changement -> Prolonger la validit√©.

---

## 5. Impl√©mentation Concr√®te (Next Steps)

1.  **Modifier le Sch√©ma DB** : Ajouter `source_date` et `validity_score` √† la table `context_sources` ou `vectors`.
2.  **Cr√©er le Script d'Ingestion** : Un script Node.js qui parse vos fichiers `.mbox` ou `.pst` (emails) et les envoie √† l'API d'ingestion.
3.  **Configurer la Query** : Modifier `src/app/actions/search.ts` pour inclure la logique de *Decay* dans la requ√™te Supabase (via une fonction RPC Postgres).
